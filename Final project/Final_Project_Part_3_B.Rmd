---
title: "Final_Project_Part_3_B"
author: "Peng Yuan"
date: '2023-04-22'
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Classification â€“ iiiC) GLM Predictions
### 1. Load package, data and model
#### 1.1 Load package
```{r,1.1_solution}
library(tidyverse)
library(caret)
library(coefplot)
library(rstanarm)
library(splines)
```

#### 1.2 Load data
```{r,1.2_solution}
df_all <- readr::read_csv("paint_project_train_data.csv", col_names = TRUE)


df <- df_all %>%
  subset(select = c(R, G, B, Hue)) %>% 
  scale() %>% as.data.frame() %>%
  bind_cols(df_all %>% subset(select = c(Lightness, Saturation, outcome)))

dfiii <- df %>% 
  mutate(outcome = ifelse(outcome == 1, 'event', 'non_event'),
         outcome = factor(outcome, levels = c('event', 'non_event')))

dfiii %>% glimpse()
```

#### 1.3 Load model
```{r}
mod6_glm <- readr::read_rds("Model/calss_glm_mod6.rds")
mod8_glm <- readr::read_rds("Model/calss_glm_mod8.rds")
```


### 2. Fit model
#### 2.1 Model 6
```{r}
class_stan_glm_mod6 <- stan_glm(formula(mod6_glm), 
                         data = dfiii,
                         family = binomial(link = "logit"),
                         prior_intercept = NULL,
                         refresh = 0,
                         seed = 123123,
                         chains = 1, 
                         iter = 300)
```

```{r}
as.data.frame(class_stan_glm_mod6) %>% tibble::as_tibble() %>% 
  select(all_of(names(class_stan_glm_mod6$coefficients))) %>% 
  tibble::rowid_to_column("post_id") %>% 
  pivot_longer(!c("post_id")) %>% 
  ggplot(mapping = aes(x = value)) +
  geom_histogram(bins = 55) +
  facet_wrap(~name, scales = "free") +
  theme_bw() +
  theme(axis.text.y = element_blank())
```

#### 2.2 Model 8

```{r}
class_stan_glm_mod8 <- stan_glm(formula(mod8_glm), 
                         data = dfiii,
                         family = binomial(link = "logit"),
                         prior_intercept = NULL,
                         refresh = 0,
                         seed = 123123,
                         chains = 1, 
                         iter = 300)
```


```{r}
as.data.frame(class_stan_glm_mod8) %>% tibble::as_tibble() %>% 
  select(all_of(names(class_stan_glm_mod8$coefficients))) %>% 
  tibble::rowid_to_column("post_id") %>% 
  pivot_longer(!c("post_id")) %>% 
  ggplot(mapping = aes(x = value)) +
  geom_histogram(bins = 55) +
  facet_wrap(~name, scales = "free") +
  theme_bw() +
  theme(axis.text.y = element_blank())
```




```{r}
class_stan_glm_mod6 %>% readr::write_rds('Model/class_stan_glm_mod6.rds')
class_stan_glm_mod8 %>% readr::write_rds('Model/class_stan_glm_mod8.rds')
```





### 3. Model Selection
#### 3.1 WAIC Evaluation
```{r}
class_stan_glm_mod6$waic <- waic(class_stan_glm_mod6)
class_stan_glm_mod8$waic <- waic(class_stan_glm_mod8)
```

```{r}
loo_class_stan_glm_mod6 <- loo(class_stan_glm_mod6)
loo_class_stan_glm_mod8 <- loo(class_stan_glm_mod8)
```

```{r}
plot(loo_class_stan_glm_mod6, label_points = TRUE)
```

```{r}
plot(loo_class_stan_glm_mod8, label_points = TRUE)
```

```{r}
loo_compare(loo_class_stan_glm_mod6, loo_class_stan_glm_mod8)
```

```{r}
k6 <- kfold(class_stan_glm_mod6)
k8 <- kfold(class_stan_glm_mod8)
```

```{r}
loo_compare(k6, k8)
```

Based on the result, I think model 6 is better.

#### 3.2 Coefficient significance
```{r}
plot(class_stan_glm_mod6,  
     pars = names(class_stan_glm_mod6$coefficients)) +
  geom_vline(xintercept = 0, color = "grey", linetype = "dashed", size = 1.) +
  theme_bw()
```

Based on the coeddicient result, I think the R is the most important features. And in combination with partii A, the continuous variables alone appear to have a very important effect on the model.














